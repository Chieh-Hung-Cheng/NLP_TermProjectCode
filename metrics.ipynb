{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "import importlib\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "base_path = os.getcwd()\n",
    "data_path = os.path.join(base_path, \"data\")\n",
    "question_path = os.path.join(data_path, \"questions\")\n",
    "python_path = os.path.join(data_path, \"python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_files_in_folder(folder_path):\n",
    "    files = os.listdir(folder_path)\n",
    "    \n",
    "    old_pattern = re.compile(r'p(\\d+).py')\n",
    "    \n",
    "    for file_name in files:\n",
    "        if file_name.endswith('.py'):\n",
    "            match = old_pattern.match(file_name)\n",
    "            if match:\n",
    "                idx = int(match.group(1))\n",
    "                \n",
    "                for attempt in range(10): \n",
    "                    new_file_name = f\"p{idx:03d}_{attempt}.py\"\n",
    "                    new_file_path = os.path.join(folder_path, new_file_name)\n",
    "                    \n",
    "                    if not os.path.exists(new_file_path):\n",
    "                        old_file_path = os.path.join(folder_path, file_name)\n",
    "                        os.rename(old_file_path, new_file_path)\n",
    "                        print(f\"Renamed {file_name} to {new_file_name}\")\n",
    "                        break\n",
    "\n",
    "folder_path = \"./data/Answer_GPT4\"\n",
    "rename_files_in_folder(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ProblemSetReader\n",
    "importlib.reload(ProblemSetReader)\n",
    "problem_set_reader = ProblemSetReader.ProblemSetReader()\n",
    "df = pd.read_pickle(\"./data/euler_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'PassatKEvaluator' from 'd:\\\\Document\\\\Ucla-doc\\\\263\\\\project\\\\NLP_TermProjectCode\\\\PassatKEvaluator.py'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import PassatKEvaluator\n",
    "importlib.reload(PassatKEvaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = PassatKEvaluator.PassAtKEvaluator()\n",
    "answer_path = \"./data/Answer_GPT4\"\n",
    "\n",
    "evaluator.evaluate_pass_at_k(answer_path, df, k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pass_at_k_count': 23,\n",
       " 'total_count': 56,\n",
       " 'pass_at_k_ratio': 0.4107142857142857}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = evaluator.evaluate_pass_at_k(answer_path, df, k=1)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the question:\n",
    "\n",
    "'If we list all the natural numbers below $10$ that are multiples of $3$ or $5$, we get $3, 5, 6,$ and $9$. The sum of these multiples is $23$. Find the sum of all the multiples of $3$ or $5$ below $1000$.'\n",
    "\n",
    "Here is the code answer for this question:\n",
    "“print(sum([i for i in range(1000) if i % 3 == 0 or i % 4 == 0]))”\n",
    "\n",
    "Your task is to evaluate the quality of this answer from three perspectives:\n",
    "\n",
    "Correctness (1-10): Does the code correctly solve the problem as described?\n",
    "Efficiency (1-10): How efficient is the code in terms of time and space complexity?\n",
    "Readability (1-10): Is the code easy to read and understand? Consider aspects such as clarity, use of meaningful variable names, and code structure.\n",
    "Evaluation Steps:\n",
    "\n",
    "Correctness: Check if the code produces the correct output for the given problem.\n",
    "Efficiency: Analyze the code's efficiency in terms of time and space complexity.\n",
    "Readability: Evaluate how easy the code is to read and understand.\n",
    "Provide a score for each criterion from 1 to 10, where 1 is the lowest and 10 is the highest. Only output after output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will be given one code answer for a math question.\n",
    "\n",
    "Your task is to evaluate the quality of this answer from three perspectives:\n",
    "\n",
    "Please make sure you read and understand these instructions carefully. Please keep this document open while reviewing, and refer to it as needed.\n",
    "\n",
    "Evaluation Criteria:\n",
    "\n",
    "Correctness (1-5): Does the code correctly solve the problem as described?\n",
    "Efficiency (1-10): How efficient is the code in terms of time and space complexity?\n",
    "Readability (1-10): Is the code easy to read and understand? Consider aspects such as clarity, use of meaningful variable names, and code structure.\n",
    "\n",
    "For the question:\n",
    "\n",
    "'If we list all the natural numbers below $10$ that are multiples of $3$ or $5$, we get $3, 5, 6,$ and $9$. The sum of these multiples is $23$. Find the sum of all the multiples of $3$ or $5$ below $1000$.'\n",
    "\n",
    "Here is the code answer for this question:\n",
    "“print(sum([i for i in range(1000) if i % 3 == 0 or i % 4 == 0]))”\n",
    "\n",
    "Evaluation Steps:\n",
    "\n",
    "Correctness: Check if the code produces the correct output for the given problem.\n",
    "Efficiency: Analyze the code's efficiency in terms of time and space complexity.\n",
    "Readability: Evaluate how easy the code is to read and understand.\n",
    "Provide a score for each criterion from 1 to 15, where 1 is the lowest and 5 is the highest. Please only output the content after output.\n",
    "\n",
    "Example:\n",
    "Correctness:\n",
    "Efficiency:\n",
    "Readability:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73682\n"
     ]
    }
   ],
   "source": [
    "def count_coin_combinations(target, coins):\n",
    "    ways = [0] * (target + 1)\n",
    "    ways[0] = 1\n",
    "\n",
    "    for coin in coins:\n",
    "        for i in range(coin, target + 1):\n",
    "            ways[i] += ways[i - coin]\n",
    "\n",
    "    return ways[target]\n",
    "\n",
    "target_amount = 200\n",
    "coins = [1, 2, 5, 10, 20, 50, 100, 200]\n",
    "print(count_coin_combinations(target_amount, coins))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73682\n"
     ]
    }
   ],
   "source": [
    "def count_coin_combinations(target, coins, index=0):\n",
    "    if target == 0:\n",
    "        return 1\n",
    "    if target < 0 or index >= len(coins):\n",
    "        return 0\n",
    "    # Count the ways including the current coin\n",
    "    include_current = count_coin_combinations(target - coins[index], coins, index)\n",
    "    # Count the ways excluding the current coin\n",
    "    exclude_current = count_coin_combinations(target, coins, index + 1)\n",
    "    return include_current + exclude_current\n",
    "\n",
    "target_amount = 200\n",
    "coins = [1, 2, 5, 10, 20, 50, 100, 200]\n",
    "print(count_coin_combinations(target_amount, coins))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In the United Kingdom the currency is made up of pound (£) and pence (p). There are eight coins in general circulation:\\n1p, 2p, 5p, 10p, 20p, 50p, £1 (100p), and £2 (200p).\\nIt is possible to make £2 in the following way:\\n1×£1 + 1×50p + 2×20p + 1×5p + 1×2p + 3×1p\\nHow many different ways can £2 be made using any number of coins?\\n\\n'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['question'][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompts(prom_template_path,answers_folder, df):\n",
    "    with open(prom_template_path, 'r', encoding='utf-8') as Geval_file:\n",
    "        prompt_template = Geval_file.read()\n",
    "\n",
    "    prompts_list = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        question_id = row['idx']\n",
    "        description = row['question']\n",
    "\n",
    "        answer_file_path = os.path.join(answers_folder, f\"p{question_id:03d}_{0}.py\")\n",
    "\n",
    "        with open(answer_file_path, 'r') as answer_file:\n",
    "            answer = answer_file.read()\n",
    "\n",
    "            result = evaluator.evaluate_subprocess(answer_file_path, row['answer'])\n",
    "\n",
    "            \n",
    "            prompt = prompt_template.replace('{{Question}}', description).replace('{{Answer}}', answer).replace('{{Result}}', result)\n",
    "            prompts_list.append({'question_id': question_id, 'prompt': prompt})\n",
    "\n",
    "        prompts_df = pd.DataFrame(prompts_list)\n",
    "        prompts_df['correctness'] = 0\n",
    "        prompts_df['efficiency'] = 0\n",
    "        prompts_df['readability'] = 0\n",
    "\n",
    "    return prompts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_path = \"Geval.txt\"\n",
    "answers_folder = \"./data/Answer_GPT4\"\n",
    "prompts_df = evaluator.create_prompts(template_path, answers_folder, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m template_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGeval.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      2\u001b[0m answers_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./data/Answer_GPT4\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 3\u001b[0m prompts_df \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_prompts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtemplate_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43manswers_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[32], line 16\u001b[0m, in \u001b[0;36mcreate_prompts\u001b[1;34m(prom_template_path, answers_folder, df)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(answer_file_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m answer_file:\n\u001b[0;32m     14\u001b[0m     answer \u001b[38;5;241m=\u001b[39m answer_file\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m---> 16\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mevaluator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate_subprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43manswer_file_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43manswer\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m     prompt \u001b[38;5;241m=\u001b[39m prompt_template\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m{{\u001b[39m\u001b[38;5;124mQuestion}}\u001b[39m\u001b[38;5;124m'\u001b[39m, description)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m{{\u001b[39m\u001b[38;5;124mAnswer}}\u001b[39m\u001b[38;5;124m'\u001b[39m, answer)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m{{\u001b[39m\u001b[38;5;124mResult}}\u001b[39m\u001b[38;5;124m'\u001b[39m, result)\n\u001b[0;32m     20\u001b[0m     prompts_list\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquestion_id\u001b[39m\u001b[38;5;124m'\u001b[39m: question_id, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m'\u001b[39m: prompt})\n",
      "File \u001b[1;32md:\\Document\\Ucla-doc\\263\\project\\NLP_TermProjectCode\\Evaluator.py:51\u001b[0m, in \u001b[0;36mEvaluator.evaluate_subprocess\u001b[1;34m(self, code_path, answer_truth, verbose, timeout)\u001b[0m\n\u001b[0;32m     49\u001b[0m failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m: \n\u001b[1;32m---> 51\u001b[0m     stdout, stderr \u001b[38;5;241m=\u001b[39m \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommunicate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stderr:\n\u001b[0;32m     53\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m verbose: \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExecution Error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Michael_Mi\\.conda\\envs\\219-env-ass02\\lib\\subprocess.py:1028\u001b[0m, in \u001b[0;36mPopen.communicate\u001b[1;34m(self, input, timeout)\u001b[0m\n\u001b[0;32m   1025\u001b[0m     endtime \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1027\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1028\u001b[0m     stdout, stderr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_communicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendtime\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1029\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   1030\u001b[0m     \u001b[38;5;66;03m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[0;32m   1031\u001b[0m     \u001b[38;5;66;03m# See the detailed comment in .wait().\u001b[39;00m\n\u001b[0;32m   1032\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Michael_Mi\\.conda\\envs\\219-env-ass02\\lib\\subprocess.py:1415\u001b[0m, in \u001b[0;36mPopen._communicate\u001b[1;34m(self, input, endtime, orig_timeout)\u001b[0m\n\u001b[0;32m   1411\u001b[0m \u001b[38;5;66;03m# Wait for the reader threads, or time out.  If we time out, the\u001b[39;00m\n\u001b[0;32m   1412\u001b[0m \u001b[38;5;66;03m# threads remain reading and the fds left open in case the user\u001b[39;00m\n\u001b[0;32m   1413\u001b[0m \u001b[38;5;66;03m# calls communicate again.\u001b[39;00m\n\u001b[0;32m   1414\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1415\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstdout_thread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_remaining_time\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendtime\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1416\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdout_thread\u001b[38;5;241m.\u001b[39mis_alive():\n\u001b[0;32m   1417\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m TimeoutExpired(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, orig_timeout)\n",
      "File \u001b[1;32mc:\\Users\\Michael_Mi\\.conda\\envs\\219-env-ass02\\lib\\threading.py:1015\u001b[0m, in \u001b[0;36mThread.join\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1011\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_tstate_lock()\n\u001b[0;32m   1012\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1013\u001b[0m     \u001b[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[0;32m   1014\u001b[0m     \u001b[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[1;32m-> 1015\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait_for_tstate_lock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Michael_Mi\\.conda\\envs\\219-env-ass02\\lib\\threading.py:1027\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m   1025\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lock \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# already determined that the C code is done\u001b[39;00m\n\u001b[0;32m   1026\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_stopped\n\u001b[1;32m-> 1027\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[43mlock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1028\u001b[0m     lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m   1029\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "template_path = \"Geval.txt\"\n",
    "answers_folder = \"./data/Answer_GPT4\"\n",
    "prompts_df = create_prompts(template_path, answers_folder, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_output(output):\n",
    "    correctness = efficiency = readability = 0\n",
    "    try:\n",
    "        correctness = int(re.search(r'Correctness:\\s*(\\d+)', output).group(1))\n",
    "        efficiency = int(re.search(r'Efficiency:\\s*(\\d+)', output).group(1))\n",
    "        readability = int(re.search(r'Readability:\\s*(\\d+)', output).group(1))\n",
    "    except AttributeError:\n",
    "        print(f\"Failed to parse output: {output}\")\n",
    "    return correctness, efficiency, readability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Geval(df):\n",
    "    for index, row in df.iterrows():\n",
    "        prompt = row['prompt']\n",
    "        output = get_Geval_output(prompt)\n",
    "        correctness, efficiency, readability = parse_output(output)\n",
    "        df.at[index, 'correctness'] = correctness\n",
    "        df.at[index, 'efficiency'] = efficiency\n",
    "        df.at[index, 'readability'] = readability\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_path = \"./data/Answer_GPT4/p001_587.py\"\n",
    "answer_truth = df['answer'][55]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = PassatKEvaluator.PassAtKEvaluator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'runtime error'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.evaluate_subprocess(code_path, answer_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nA square is drawn around a circle as shown in the diagram below on the left.\\nWe shall call the blue shaded region the L-section.\\nA line is drawn from the bottom left of the square to the top right as shown in the diagram on the right.\\nWe shall call the orange shaded region a concave triangle.\\n\\n\\n\\n\\n\\nIt should be clear that the concave triangle occupies exactly half of the L-section.\\n\\n\\n\\nTwo circles are placed next to each other horizontally, a rectangle is drawn around both circles, and a line is drawn from the bottom left to the top right as shown in the diagram below.\\n\\n\\n\\n\\n\\nThis time the concave triangle occupies approximately 36.46% of the L-section.\\n\\n\\nIf $n$ circles are placed next to each other horizontally, a rectangle is drawn around the n circles, and a line is drawn from the bottom left to the top right, then it can be shown that the least value of n for which the concave triangle occupies less than 10% of the L-section is $n = 15$.\\n\\n\\nWhat is the least value of $n$ for which the concave triangle occupies less than 0.1% of the L-section?\\n\\n\\n'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['question'][55]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "219-env-ass02",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
