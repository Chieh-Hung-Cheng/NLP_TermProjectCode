{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import importlib\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import DataProcessor\n",
    "importlib.reload(DataProcessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_processor = DataProcessor.DataProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_processor.get_euler_dataframe()\n",
    "# save df\n",
    "df.to_pickle(\"/data/euler_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load df from pickle\n",
    "df = pd.read_pickle(\"./data/euler_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test CodeT5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5ForConditionalGeneration, RobertaTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained('Salesforce/codet5-small')\n",
    "model = T5ForConditionalGeneration.from_pretrained('Salesforce/codet5-small')\n",
    "\n",
    "text = \"def greet(user): print(f'hello <extra_id_0>!')\"\n",
    "input_ids = tokenizer(text, return_tensors=\"pt\").input_ids\n",
    "\n",
    "# simply generate a single sequence\n",
    "generated_ids = model.generate(input_ids, max_length=10)\n",
    "print(tokenizer.decode(generated_ids[0], skip_special_tokens=True))\n",
    "# this prints \"user: {user.name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer(text, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode(generated_ids[0][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ProblemSetReader\n",
    "importlib.reload(ProblemSetReader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_set_reader = ProblemSetReader.ProblemSetReader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question, answer, code = problem_set_reader.get_problem_set(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tokenizer(question, return_tensors=\"pt\").input_ids\n",
    "generated_ids = model.generate(input_ids, max_length=500)\n",
    "print(tokenizer.decode(generated_ids[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test CodeGen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_str = \"2B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(f\"Salesforce/codegen-{size_str}-mono\")\n",
    "model = AutoModelForCausalLM.from_pretrained(f\"Salesforce/codegen-{size_str}-mono\",\n",
    "                                             output_hidden_states=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prime $41$, can be written as the sum of six consecutive primes:\n",
      "$$41 = 2 + 3 + 5 + 7 + 11 + 13.$$\n",
      "This is the longest sum of consecutive primes that adds to a prime below one-hundred.\n",
      "The longest sum of consecutive primes below one-thousand that adds to a prime, contains $21$ terms, and is equal to $953$.\n",
      "Which prime, below one-million, can be written as the sum of the most consecutive primes?\n",
      "\"\"\"\n",
      "\n",
      "from math import sqrt\n",
      "\n",
      "def is_prime(n):\n",
      "    if n == 1:\n",
      "        return False\n",
      "    for i in range(2, int(sqrt(n)) + 1):\n",
      "        if n % i == 0:\n",
      "            return False\n",
      "    return True\n",
      "\n",
      "def solution(limit):\n",
      "    primes = []\n",
      "    for i in range(2, limit):\n",
      "        if is_prime(i):\n",
      "            primes.append(i)\n",
      "    \n",
      "    max_prime = 0\n",
      "    max_prime_sum = 0\n",
      "    for i in range(len(primes)):\n",
      "        for j in range(i, len(primes)):\n",
      "            sum = primes[i] + primes[j]\n",
      "            if sum < limit:\n",
      "                if is_prime(sum):\n",
      "                    if sum > max_prime_sum:\n",
      "                        max_prime_sum = sum\n",
      "                        max_prime = primes[i] + primes[j]\n",
      "    return max_prime\n",
      "\n",
      "print(solution(1000000))\n",
      "<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "text = problem_set_reader.get_question(50)+\"\\\"\\\"\\\"\"\n",
    "input_ids = tokenizer(text, return_tensors=\"pt\").input_ids\n",
    "\n",
    "completion = model.generate(**tokenizer(text, return_tensors=\"pt\"), \n",
    "                            max_length=512)\n",
    "print(tokenizer.decode(completion[0][:len(text)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "from math import sqrt\n",
      "\n",
      "def is_prime(n):\n",
      "    if n == 1:\n",
      "        return False\n",
      "    for i in range(2, int(sqrt(n)) + 1):\n",
      "        if n % i == 0:\n",
      "            return False\n",
      "    return True\n",
      "\n",
      "def solution(limit):\n",
      "    primes = []\n",
      "    for i in range(2, limit):\n",
      "        if is_prime(i):\n",
      "            primes.append(i)\n",
      "    \n",
      "    max_prime = 0\n",
      "    max_prime_sum = 0\n",
      "    for i in range(len(primes)):\n",
      "        for j in range(i, len(primes)):\n",
      "            sum = primes[i] + primes[j]\n",
      "            if sum < limit:\n",
      "                if is_prime(sum):\n",
      "                    if sum > max_prime_sum:\n",
      "                        max_prime_sum = sum\n",
      "                        max_prime = primes[i] + primes[j]\n",
      "    return max_prime\n",
      "\n",
      "print(solution(1000000))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(completion[0][len(input_ids[0]):][:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_path = os.path.join(os.getcwd(), \"data\", \"generated\")\n",
    "if not os.path.isdir(generated_path):\n",
    "    os.mkdir(generated_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 50\n",
    "generated_code_str = tokenizer.decode(completion[0][len(input_ids[0]):][:-1])\n",
    "\n",
    "with open(os.path.join(generated_path, f\"p{idx:03d}.py\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(generated_code_str)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
